{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fab98bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b78bdcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.saved_model.load(tags=['serve'], export_dir=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b84bd9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_fn=model.signatures[\"serving_default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05755536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Confidences': {'dtype': 'float32',\n",
       "  'shape': [None, 6],\n",
       "  'name': '62da264a-5079-4029-a2a7-ac824da0be1d.3dcb847f-69e8-4aca-ac1b-872314e1d1ce/dense_2/Softmax:0'}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('signature.json',)\n",
    "signature = json.load(f)\n",
    "inputs=signature.get(\"inputs\")\n",
    "outputs=signature.get(\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "15aeecb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image: Image.Image) -> dict:\n",
    "    # pre-processing the image before passing to model\n",
    "    image = process_image(image, inputs.get(\"Image\").get(\"shape\"))\n",
    "    feed_dict = {}\n",
    "    feed_dict[list(inputs.keys())[0]] = tf.convert_to_tensor(image)\n",
    "    outputs = predict_fn(**feed_dict)\n",
    "    return process_output(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "70f70264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image, input_shape) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    center square crop and resize to fit the expected model input, and convert from [0,255] to [0,1] values.\n",
    "    \"\"\"\n",
    "    width, height = image.size\n",
    "    # ensure image type is compatible with model and convert if not\n",
    "    if image.mode != \"RGB\":\n",
    "        image = image.convert(\"RGB\")\n",
    "    # center crop image\n",
    "    if width != height:\n",
    "        square_size = min(width, height)\n",
    "        left = (width - square_size) / 2\n",
    "        top = (height - square_size) / 2\n",
    "        right = (width + square_size) / 2\n",
    "        bottom = (height + square_size) / 2\n",
    "        # Crop the center of the image\n",
    "        image = image.crop((left, top, right, bottom))\n",
    "    # now the image is square, resize it to be the right shape for the model input\n",
    "    input_width, input_height = input_shape[1:3]\n",
    "    if image.width != input_width or image.height != input_height:\n",
    "        image = image.resize((input_width, input_height))\n",
    "\n",
    "    # make 0-1 float instead of 0-255 int (that PIL Image loads by default)\n",
    "    image = np.asarray(image) / 255.0\n",
    "    # pad with an extra batch dimension as expected by the model\n",
    "    return np.expand_dims(image, axis=0).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "652754e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_output(outputs) -> dict:\n",
    "        #postprocessing\n",
    "        out_keys = [\"label\", \"confidence\"]\n",
    "        results = {}\n",
    "        for key, tf_val in outputs.items():\n",
    "            val = tf_val.numpy().tolist()[0]\n",
    "            if isinstance(val, bytes):\n",
    "                val = val.decode()\n",
    "            results[key] = val\n",
    "        confs = results[\"Confidences\"]\n",
    "        labels = signature.get(\"classes\").get(\"Label\")\n",
    "        output = [dict(zip(out_keys, group)) for group in zip(labels, confs)]\n",
    "        sorted_output = {\"predictions\": sorted(output, key=lambda k: k[\"confidence\"], reverse=True)}\n",
    "        return sorted_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "56797ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=Image.open(\"./1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2dcffac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'label': 'audi car images',\n",
       "   'confidence': 0.9497203230857849},\n",
       "  {'label': 'bmw car images', 'confidence': 0.03611782193183899},\n",
       "  {'label': 'mercedes car images', 'confidence': 0.011200593784451485},\n",
       "  {'label': 'maruti suzuki car images', 'confidence': 0.0023138721007853746},\n",
       "  {'label': 'hyundai car images', 'confidence': 0.0006463660392910242},\n",
       "  {'label': 'lamborghini car images', 'confidence': 1.133359319283045e-06}]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b8c0b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
